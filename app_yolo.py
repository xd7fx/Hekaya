import os
import tempfile
import cv2
import numpy as np
import streamlit as st
from PIL import Image
from ultralytics import YOLO

def run_yolo_app():
    st.title("ğŸ”  Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… YOLO")

    model_choice = st.selectbox("ğŸ§  Ø§Ø®ØªØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„", ["ğŸ”¤ 4 Ø£Ø­Ø±Ù ÙÙ‚Ø· (best2)", "ğŸ”¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø­Ø±Ù (best3)"])
    model_path = "C:/Users/d7fx9/HEKAYA/best2.pt" if "best2" in model_choice else "C:/Users/d7fx9/HEKAYA/best3.pt"
    model = YOLO(model_path)

    label_map = {
        "A": "Ø£", "B": "Ø¨", "T": "Øª", "TH": "Ø«", "J": "Ø¬", "HA": "Ø­", "KH": "Ø®", "D": "Ø¯",
        "THL": "Ø°", "R": "Ø±", "Z": "Ø²", "S": "Ø³", "SH": "Ø´", "SD": "Øµ", "TD": "Ø¶", "TA": "Ø·",
        "AN": "Ø¹", "QN": "Øº", "F": "Ù", "QA": "Ù‚", "K": "Ùƒ", "L": "Ù„", "M": "Ù…", "N": "Ù†",
        "H": "Ù‡", "W": "Ùˆ", "E": "ÙŠ", "SPACE": " "
    }

    input_method = st.radio("ğŸ¯ Ù…ØµØ¯Ø± Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„", ["ğŸ“ Ø±ÙØ¹ ØµÙˆØ±Ø©", "ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§"])
    uploaded_file = None
    if input_method == "ğŸ“ Ø±ÙØ¹ ØµÙˆØ±Ø©":
        uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø©", type=["jpg", "jpeg", "png"])
    elif input_method == "ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§":
        uploaded_file = st.camera_input("Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§")

    if uploaded_file:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©", use_container_width=True)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as temp:
            image.save(temp.name)
            image_path = temp.name

        results = model.predict(image_path, imgsz=896, save=False)[0]
        boxes = results.boxes
        names = model.names

        xyxy = boxes.xyxy.cpu().numpy()
        conf = boxes.conf.cpu().numpy()
        cls = boxes.cls.cpu().numpy().astype(int)

        bboxes = [[int(x[0]), int(x[1]), int(x[2] - x[0]), int(x[3] - x[1])] for x in xyxy]
        indices = cv2.dnn.NMSBoxes(bboxes, conf.tolist(), score_threshold=0.1, nms_threshold=0.3)

        final = []
        seen = set()
        if len(indices) > 0:
            indices = indices.flatten()
            for i in indices:
                x_center = (xyxy[i][0] + xyxy[i][2]) / 2
                key = int(x_center // 60)
                if key not in seen:
                    seen.add(key)
                    final.append((x_center, names[cls[i]], conf[i]))

        sorted_final = sorted(final, key=lambda x: -x[0])
        letters = [l for _, l, _ in sorted_final]

        st.subheader("ğŸ”  Ø§Ù„Ù†ØªÙŠØ¬Ø© (Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø±):")
        st.success(" ".join(letters))

        arabic_letters = [label_map.get(l, l) for l in letters]
        st.subheader("ğŸ—£ï¸ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:")
        st.success("".join(arabic_letters))

        image_np = np.array(image)
        for i in range(len(xyxy)):
            x1, y1, x2, y2 = map(int, xyxy[i])
            label = f"{names[cls[i]]} ({conf[i]:.2f})"
            color = (0, 255, 0)
            cv2.rectangle(image_np, (x1, y1), (x2, y2), color, 2)
            cv2.putText(image_np, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

        st.image(image_np, caption="ğŸ“¦ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ø¨Ø§ÙˆÙ†Ø¯Ø±ÙŠ Ø¨ÙˆÙƒØ³", use_container_width=True)

        with st.expander("ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¨Ø§ÙˆÙ†Ø¯Ø±ÙŠ Ø¨ÙˆÙƒØ³"):
            for i in range(len(xyxy)):
                st.info(f"{names[cls[i]]} ({conf[i]:.2f})")
