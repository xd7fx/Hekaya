import os
import time
import tempfile
import cv2
import numpy as np
import streamlit as st
from PIL import Image
from ultralytics import YOLO

st.set_page_config(page_title="Lihyanite AI Detector", layout="centered")

# ğŸ§  Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
model_choice = st.selectbox("ğŸ§  Ø§Ø®ØªØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„", ["ğŸ”¤ 4 Ø£Ø­Ø±Ù ÙÙ‚Ø· (best2)", "ğŸ”¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø­Ø±Ù (best3)"])
model_path = "best2.pt" if "best2" in model_choice else "best3.pt"
model = YOLO(model_path)

# ğŸ—ºï¸ Ù‚Ø§Ù…ÙˆØ³ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
label_map = {
    "A": "Ø£", "B": "Ø¨", "T": "Øª", "TH": "Ø«", "J": "Ø¬", "HA": "Ø­", "KH": "Ø®", "D": "Ø¯",
    "THL": "Ø°", "R": "Ø±", "Z": "Ø²", "S": "Ø³", "SH": "Ø´", "SD": "Øµ", "TD": "Ø¶", "TA": "Ø·",
    "AN": "Ø¹", "QN": "Øº", "F": "Ù", "QA": "Ù‚", "K": "Ùƒ", "L": "Ù„", "M": "Ù…", "N": "Ù†",
    "H": "Ù‡", "W": "Ùˆ", "E": "ÙŠ", "SPACE": " "
}

st.title("ğŸ“· AI Letter Detection")
input_method = st.radio("ğŸ¯ Ù…ØµØ¯Ø± Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„", ["ğŸ“ Ø±ÙØ¹ ØµÙˆØ±Ø©", "ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§"])

# ğŸ“ Ø±ÙØ¹ ØµÙˆØ±Ø© Ø£Ùˆ ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§
uploaded_file = None
if input_method == "ğŸ“ Ø±ÙØ¹ ØµÙˆØ±Ø©":
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø©", type=["jpg", "jpeg", "png"])
elif input_method == "ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§":
    uploaded_file = st.camera_input("Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø© Ø¨Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§")

# âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±Ø© Ø«Ø§Ø¨ØªØ©
if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    if input_method == "ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§":
        image = image.rotate(-90, expand=True)  # ØªØ¯ÙˆÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ù„ØªÙƒÙˆÙ† Ø¨Ø§Ù„Ø¹Ø±Ø¶
    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©", use_container_width=True)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as temp:
        image.save(temp.name)
        image_path = temp.name

    results = model.predict(image_path, imgsz=896, save=False)[0]
    boxes = results.boxes
    names = model.names

    xyxy = boxes.xyxy.cpu().numpy()
    conf = boxes.conf.cpu().numpy()
    cls = boxes.cls.cpu().numpy().astype(int)

    bboxes = [[int(x[0]), int(x[1]), int(x[2] - x[0]), int(x[3] - x[1])] for x in xyxy]
    indices = cv2.dnn.NMSBoxes(bboxes, conf.tolist(), score_threshold=0.1, nms_threshold=0.3)

    final = []
    seen = set()
    if len(indices) > 0:
        indices = indices.flatten()
        for i in indices:
            x_center = (xyxy[i][0] + xyxy[i][2]) / 2
            key = int(x_center // 60)
            if key not in seen:
                seen.add(key)
                final.append((x_center, names[cls[i]], conf[i]))

    sorted_final = sorted(final, key=lambda x: -x[0])
    letters = [l for _, l, _ in sorted_final]

    st.subheader("ğŸ”  Ø§Ù„Ù†ØªÙŠØ¬Ø© (Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø±):")
    st.success(" ".join(letters))

    # âœ¨ Ø¹Ø±Ø¶ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    arabic_letters = [label_map.get(l, l) for l in letters]
    st.subheader("ğŸ—£ï¸ Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:")
    st.success("".join(arabic_letters))

    # ğŸ“¦ Ø±Ø³Ù… Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª
    image_np = np.array(image)
    for i in range(len(xyxy)):
        x1, y1, x2, y2 = map(int, xyxy[i])
        label = f"{names[cls[i]]} ({conf[i]:.2f})"
        color = (0, 255, 0)
        cv2.rectangle(image_np, (x1, y1), (x2, y2), color, 2)
        cv2.putText(image_np, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    st.image(image_np, caption="ğŸ“¦ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ø¨Ø§ÙˆÙ†Ø¯Ø±ÙŠ Ø¨ÙˆÙƒØ³", use_container_width=True)

    with st.expander("ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¨Ø§ÙˆÙ†Ø¯Ø±ÙŠ Ø¨ÙˆÙƒØ³ Ø§Ù„ÙƒØ§Ù…Ù„Ø©"):
        for i in range(len(xyxy)):
            st.info(f"{names[cls[i]]} ({conf[i]:.2f})")
