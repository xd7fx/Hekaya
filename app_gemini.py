import streamlit as st
import os
import base64
import pandas as pd
from PIL import Image
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
def run_gemini_app():
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØªØ§Ø­
    GOOGLE_API_KEY = "AIzaSyCPjAE_mjkPZ7CF4om2VwTal68Ov-WTo1c"
    os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

    st.title("ğŸ“ Landmark Identifier | Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø§Ù„Ù…")

    # ğŸŒ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ØºØ©
    lang = st.radio("ğŸŒ Language / Ø§Ù„Ù„ØºØ©", ["ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "ğŸ‡ºğŸ‡¸ English"])

    # ğŸ·ï¸ Ù‚Ø§Ù…ÙˆØ³ Ù„ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©
    labels = {
        "ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
            "csv": "description_ar.csv",
            "prompt": "Ù…Ø§ Ø§Ø³Ù… Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØŸ",
            "upload": "ğŸ“ Ø±ÙØ¹ ØµÙˆØ±Ø©",
            "camera": "ğŸ“¸ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø©",
            "processing": "â³ ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù…...",
            "success": "âœ… ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù…:",
            "not_found": "ğŸ“Œ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ØµØ© Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹Ù„Ù… Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.",
            "story": "ğŸ“– Ø§Ù„Ù‚ØµØ©:",
            "video": "ğŸ¬ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ:"
        },
        "ğŸ‡ºğŸ‡¸ English": {
            "csv": "description_en.csv",
            "prompt": "What is the name of this historical site?",
            "upload": "ğŸ“ Upload Image",
            "camera": "ğŸ“¸ Capture Image",
            "processing": "â³ Identifying the landmark...",
            "success": "âœ… Identified:",
            "not_found": "ğŸ“Œ No story is currently available for this site.",
            "story": "ğŸ“– Story:",
            "video": "ğŸ¬ Video:"
        }
    }

    # Ø§Ø®ØªØµØ§Ø± Ø§Ù„Ù†ØµÙˆØµ
    L = labels[lang]
    csv_file = L["csv"]

    # ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    @st.cache_data
    def load_knowledge(file_path):
        df = pd.read_csv(file_path)
        df.columns = df.columns.str.strip()
        return {
            row["name"]: {
                "description": row["description"],
                "video_url": row["video_url"]
            } for _, row in df.iterrows()
        }

    knowledge_base = load_knowledge(csv_file)

    # Ø·Ø±ÙŠÙ‚Ø© Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©
    input_method = st.radio("ğŸ¯ Source", [L["upload"], L["camera"]])
    uploaded_file = None

    if input_method == L["upload"]:
        uploaded_file = st.file_uploader(L["upload"], type=["jpg", "jpeg", "png"])
    elif input_method == L["camera"]:
        uploaded_file = st.camera_input(L["camera"])

    if uploaded_file:
        image_bytes = uploaded_file.getvalue()
        image = Image.open(uploaded_file)
        st.image(image, caption="ğŸ“ Image", use_container_width=True)

        image_b64 = base64.b64encode(image_bytes).decode("utf-8")
        mime_type = uploaded_file.type

        st.info(L["processing"])

        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.3,
            google_api_key=GOOGLE_API_KEY,
        )

        msg = HumanMessage(
            content=[
                {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{image_b64}"}},
                {"type": "text", "text": L["prompt"]}
            ]
        )

        try:
            response = llm([msg])
            raw_response = response.content.strip()
            st.success(f"{L['success']} {raw_response}")

            # ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø§Ø³Ù… Ø¯Ø§Ø®Ù„ Ø§Ù„Ø±Ø¯
            matched_name = None
            for name in knowledge_base.keys():
                if name.lower() in raw_response.lower():
                    matched_name = name
                    break


            if matched_name:
                st.subheader(L["story"])
                st.write(knowledge_base[matched_name]["description"])
                st.subheader(L["video"])
                st.video(knowledge_base[matched_name]["video_url"])
            else:
                st.warning(L["not_found"])

        except Exception as e:
            st.error("âŒ Error during landmark identification.")
            st.exception(e)
