import streamlit as st
import os
import base64
import pandas as pd
import difflib
from PIL import Image
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage

def run_gemini_app():
    GOOGLE_API_KEY = "AIzaSyCPjAE_mjkPZ7CF4om2VwTal68Ov-WTo1c"
    os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

    st.title("ğŸ“ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù… Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©")

    # ğŸŒ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ØºØ©
    lang = st.radio("ğŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ©", ["ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "ğŸ‡ºğŸ‡¸ English"])
    csv_file = "description_ar.csv" if lang == "ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "description_en.csv"

    # ğŸ§  ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ù… Ù…Ù† CSV
    @st.cache_data
    def load_knowledge(file_path):
        df = pd.read_csv(file_path)
        df.columns = df.columns.str.strip()
        return {
            row["name"]: {
                "description": row["description"],
                "video_url": row["video_url"]
            } for _, row in df.iterrows()
        }

    knowledge_base = load_knowledge(csv_file)

    # ğŸ“¸ Ø§Ø®ØªÙŠØ§Ø± Ù…ØµØ¯Ø± Ø§Ù„ØµÙˆØ±Ø©
    input_method = st.radio("ğŸ¯ Ù…ØµØ¯Ø± Ø§Ù„ØµÙˆØ±Ø©", ["ğŸ“ Ø±ÙØ¹ ØµÙˆØ±Ø©", "ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§"])
    uploaded_file = None

    if input_method == "ğŸ“ Ø±ÙØ¹ ØµÙˆØ±Ø©":
        uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù„Ù…Ø¹Ù„Ù…", type=["jpg", "jpeg", "png"])
    elif input_method == "ğŸ“¸ ÙƒØ§Ù…ÙŠØ±Ø§":
        uploaded_file = st.camera_input("ğŸ“¸ Ø§Ù„ØªÙ‚Ø· ØµÙˆØ±Ø© Ù„Ù„Ù…Ø¹Ù„Ù…")

    if uploaded_file:
        image_bytes = uploaded_file.getvalue()
        image = Image.open(uploaded_file)
        st.image(image, caption="ğŸ“ Ø§Ù„ØµÙˆØ±Ø©", use_container_width=True)

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ base64
        image_b64 = base64.b64encode(image_bytes).decode("utf-8")
        mime_type = uploaded_file.type

        st.info("â³ ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù…...")

        # Ø¥Ø¹Ø¯Ø§Ø¯ LLM
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0.3,
            google_api_key=GOOGLE_API_KEY,
        )

        msg = HumanMessage(
            content=[
                {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{image_b64}"}},
                {"type": "text", "text": "Ù…Ø§ Ø§Ø³Ù… Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØŸ"}
            ]
        )

        try:
            response = llm([msg])
            raw_response = response.content.strip()
            st.success(f"âœ… ØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„Ù…: {raw_response}")

            # ğŸ§  ØªØ·Ø§Ø¨Ù‚ Ø°ÙƒÙŠ Ù…Ø¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ CSV
            place_name = raw_response
            match = difflib.get_close_matches(place_name, knowledge_base.keys(), n=1, cutoff=0.5)

            if match:
                matched_name = match[0]
                st.subheader("ğŸ“– Ø§Ù„Ù‚ØµØ©:" if lang == "ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "ğŸ“– Story:")
                st.write(knowledge_base[matched_name]["description"])
                st.subheader("ğŸ¬ ÙÙŠØ¯ÙŠÙˆ:")
                st.video(knowledge_base[matched_name]["video_url"])
            else:
                st.warning("ğŸ“Œ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ØµØ© Ù…Ø­ÙÙˆØ¸Ø© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹Ù„Ù… Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†.")

        except Exception as e:
            st.error("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ¹Ø±Ù.")
            st.exception(e)
